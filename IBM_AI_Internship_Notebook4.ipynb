{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "L-jy3OM3LuWB",
        "aiEoBJkEMlVy",
        "r2nPeQ6tqC9N"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Authors:\n",
        "- Abdulaziz Alakooz : Github([@3koozy](https://github.com/3koozy)).\n",
        "- Ahad Algrais : Github([@ahadalgrais](https://github.com/ahadalgrais)).\n",
        "- Mujtaba Alghadeer : Github([@ghadeem](https://github.com/ghadeem))."
      ],
      "metadata": {
        "id": "rlL11UhqGimK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFLMS5ppGY4V",
        "outputId": "733b0790-a482-406a-f46b-c476e7303cfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from rasterio) (67.6.1)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.9/dist-packages (from rasterio) (8.1.3)\n",
            "Collecting affine\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Collecting click-plugins\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.9/dist-packages (from rasterio) (1.22.4)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from rasterio) (2022.12.7)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.9/dist-packages (from rasterio) (22.2.0)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.9/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n",
            "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.3.6 snuggs-1.4.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting radiant_mlhub\n",
            "  Downloading radiant_mlhub-0.5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3~=1.26.11 in /usr/local/lib/python3.9/dist-packages (from radiant_mlhub) (1.26.15)\n",
            "Collecting pystac~=1.4.0\n",
            "  Downloading pystac-1.4.0-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from radiant_mlhub) (8.1.3)\n",
            "Collecting pydantic~=1.9.2\n",
            "  Downloading pydantic-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm~=4.64.0\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil~=2.8.2 in /usr/local/lib/python3.9/dist-packages (from radiant_mlhub) (2.8.2)\n",
            "Requirement already satisfied: requests~=2.27.0 in /usr/local/lib/python3.9/dist-packages (from radiant_mlhub) (2.27.1)\n",
            "Collecting shapely~=1.8.0\n",
            "  Downloading Shapely-1.8.5.post1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from pydantic~=1.9.2->radiant_mlhub) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil~=2.8.2->radiant_mlhub) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests~=2.27.0->radiant_mlhub) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests~=2.27.0->radiant_mlhub) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests~=2.27.0->radiant_mlhub) (2.0.12)\n",
            "Installing collected packages: tqdm, shapely, pydantic, pystac, radiant_mlhub\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: shapely\n",
            "    Found existing installation: shapely 2.0.1\n",
            "    Uninstalling shapely-2.0.1:\n",
            "      Successfully uninstalled shapely-2.0.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.7\n",
            "    Uninstalling pydantic-1.10.7:\n",
            "      Successfully uninstalled pydantic-1.10.7\n",
            "Successfully installed pydantic-1.9.2 pystac-1.4.0 radiant_mlhub-0.5.5 shapely-1.8.5.post1 tqdm-4.64.1\n"
          ]
        }
      ],
      "source": [
        "#Prequisites:\n",
        "!pip install rasterio\n",
        "!pip install radiant_mlhub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import needed libraries:\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import getpass\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from radiant_mlhub import Dataset\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.base import is_classifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "BCNSKnv1Glpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['MLHUB_API_KEY'] = 'f31d9911aff9a7ba88e4be73b25a41f960393cf31c5745da97b7f54bf31a1f62'"
      ],
      "metadata": {
        "id": "3mkAoJYwJh_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AgriFieldNet Dataset / Competition"
      ],
      "metadata": {
        "id": "xhiDjkjMJA8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link to compeition and dataset description](https://zindi.africa/competitions/agrifieldnet-india-challenge)"
      ],
      "metadata": {
        "id": "9LPJ_oTDJQ2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Small farms (<2ha) produce about 35% of the world’s food, and are mostly found in low- and middle-income countries. Reliable information about these farms is limited, making support and policy-making difficult. Earth Observation data from satellites such as Sentinel-2, in combination with machine learning, can help improve agricultural monitoring, crop mapping, and disaster risk management for these small farms."
      ],
      "metadata": {
        "id": "74Z0B6-VJE-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The label chips contain the mapping of pixels to crop type labels. The following pixel values correspond to the following crop types:\n",
        "\n",
        "* 1 - Wheat\n",
        "* 2 - Mustard\n",
        "* 3 - Lentil\n",
        "* 4 - No Crop/Fallow\n",
        "* 5 - Green pea\n",
        "* 6 - Sugarcane\n",
        "* 8 - Garlic\n",
        "* 9 - Maize\n",
        "* 13 - Gram\n",
        "* 14 - Coriander\n",
        "* 15 - Potato\n",
        "* 16 - Bersem\n",
        "* 36 - Rice\n",
        "\n",
        "for some models we need to re-label these classes in ascending order without any gaps."
      ],
      "metadata": {
        "id": "rNXY_dyLqeHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** this notebook has been heavily inspired by this starter notebook ([link here](https://github.com/radiantearth/agrifieldnet_india_competition/blob/main/Starter%20notebook.ipynb))."
      ],
      "metadata": {
        "id": "7Zsa72xnJpYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the dataset:"
      ],
      "metadata": {
        "id": "RBZBWGocK0Uh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select desired bands \n",
        "\n",
        "all_bands = ['B01', 'B02', 'B03', 'B04','B05', 'B06', 'B07', 'B08','B8A', 'B09', 'B11', 'B12']\n",
        "\n",
        "selected_bands = all_bands#all_bands[1:4]  + [all_bands[7]] \n",
        "selected_bands"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3jepiFIJljw",
        "outputId": "039b709d-51bd-4e04-fed6-22131d8a3e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B01',\n",
              " 'B02',\n",
              " 'B03',\n",
              " 'B04',\n",
              " 'B05',\n",
              " 'B06',\n",
              " 'B07',\n",
              " 'B08',\n",
              " 'B8A',\n",
              " 'B09',\n",
              " 'B11',\n",
              " 'B12']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset collection_id, desired assets, and collections\n",
        "\n",
        "main = 'ref_agrifieldnet_competition_v1'\n",
        "\n",
        "assets = ['field_ids','raster_labels']\n",
        "\n",
        "source_collection = f'{main}_source'\n",
        "train_label_collection = f'{main}_labels_train'\n",
        "test_label_collection = f'{main}_labels_test'\n",
        "\n",
        "dataset = Dataset.fetch(main)\n",
        "\n",
        "my_filter = dict(\n",
        "    ref_agrifieldnet_competition_v1_labels_train=assets,\n",
        "\n",
        "    ref_agrifieldnet_competition_v1_labels_test=[assets[0]],\n",
        "\n",
        "    ref_agrifieldnet_competition_v1_source=selected_bands \n",
        ")\n",
        "\n",
        "dataset.download(collection_filter=my_filter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnYTx6yIJnQW",
        "outputId": "958c9be2-8399-4ca6-aa71-7612fd15ef59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ref_agrifieldnet_competition_v1: fetch stac catalog: 1044KB [00:01, 679.90KB/s]                          \n",
            "unarchive ref_agrifieldnet_competition_v1.tar.gz: 100%|██████████| 6186/6186 [00:01<00:00, 4541.93it/s]\n",
            "filter by collection ids and asset keys: 193370it [00:00, 1807855.00it/s]         \n",
            "download assets: 100%|██████████| 17643/17643 [36:50<00:00,  7.98it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load collection json and retrieve all unique folder ids \n",
        "#use all unique folder ids to create a list of field and label paths for all tiles\n",
        "\n",
        "with open (f'{main}/{train_label_collection}/collection.json') as f:\n",
        "    train_json = json.load(f)\n",
        "    \n",
        "train_folder_ids = [i['href'].split('_')[-1].split('.')[0] for i in train_json['links'][4:]]\n",
        "del train_folder_ids[-1]\n",
        "\n",
        "train_field_paths = [f'{main}/{train_label_collection}/{train_label_collection}_{i}/field_ids.tif' for i in train_folder_ids]\n",
        "train_label_paths = [f'{main}/{train_label_collection}/{train_label_collection}_{i}/raster_labels.tif' for i in train_folder_ids]"
      ],
      "metadata": {
        "id": "IHpjrOuaKG1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create dataset for folder_ids and field_paths\n",
        "\n",
        "competition_train_data = pd.DataFrame(train_folder_ids, columns=['unique_folder_id'])\n",
        "competition_train_data['field_paths'] = train_field_paths\n",
        "competition_train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ToTV5x1EKIp5",
        "outputId": "6cb17916-45eb-4420-a683-674c4f80a963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  unique_folder_id                                        field_paths\n",
              "0            28852  ref_agrifieldnet_competition_v1/ref_agrifieldn...\n",
              "1            d987c  ref_agrifieldnet_competition_v1/ref_agrifieldn...\n",
              "2            ca1d4  ref_agrifieldnet_competition_v1/ref_agrifieldn...\n",
              "3            2ec18  ref_agrifieldnet_competition_v1/ref_agrifieldn...\n",
              "4            7575d  ref_agrifieldnet_competition_v1/ref_agrifieldn..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-678a62e5-3834-464f-8bbe-f683ad213c0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_folder_id</th>\n",
              "      <th>field_paths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28852</td>\n",
              "      <td>ref_agrifieldnet_competition_v1/ref_agrifieldn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d987c</td>\n",
              "      <td>ref_agrifieldnet_competition_v1/ref_agrifieldn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ca1d4</td>\n",
              "      <td>ref_agrifieldnet_competition_v1/ref_agrifieldn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2ec18</td>\n",
              "      <td>ref_agrifieldnet_competition_v1/ref_agrifieldn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7575d</td>\n",
              "      <td>ref_agrifieldnet_competition_v1/ref_agrifieldn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-678a62e5-3834-464f-8bbe-f683ad213c0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-678a62e5-3834-464f-8bbe-f683ad213c0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-678a62e5-3834-464f-8bbe-f683ad213c0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract field_crop Pairs \n",
        "\n",
        "def field_crop_extractor(crop_field_files):\n",
        "    field_crops = {}\n",
        "\n",
        "    for label_field_file in tqdm(crop_field_files):\n",
        "        with rasterio.open(f'{main}/{train_label_collection}/{train_label_collection}_{label_field_file}/field_ids.tif') as src:\n",
        "            field_data = src.read()[0]\n",
        "        with rasterio.open(f'{main}/{train_label_collection}/{train_label_collection}_{label_field_file}/raster_labels.tif') as src:\n",
        "            crop_data = src.read()[0]\n",
        "    \n",
        "        for x in range(0, crop_data.shape[0]):\n",
        "            for y in range(0, crop_data.shape[1]):\n",
        "                field_id = str(field_data[x][y])\n",
        "                field_crop = crop_data[x][y]\n",
        "\n",
        "                if field_crops.get(field_id) is None:\n",
        "                    field_crops[field_id] = []\n",
        "\n",
        "                if field_crop not in field_crops[field_id]:\n",
        "                    field_crops[field_id].append(field_crop)\n",
        "    \n",
        "    field_crop_map  =[[k, v[0]]  for k, v in field_crops.items() ]\n",
        "    field_crop = pd.DataFrame(field_crop_map , columns=['field_id','crop_id'])\n",
        "\n",
        "    return field_crop[field_crop['field_id']!='0']"
      ],
      "metadata": {
        "id": "9fJexWg1Knrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field_crop_pair = field_crop_extractor(train_folder_ids)\n",
        "field_crop_pair.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "zTd8BhSEKpsg",
        "outputId": "6a9e31bf-1d55-46b0-826a-56f02774c13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1165/1165 [02:04<00:00,  9.32it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  field_id  crop_id\n",
              "1      757        6\n",
              "2      756        6\n",
              "3     1372        5\n",
              "4     1374        1\n",
              "5     1986        4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-640cb9d4-6185-4545-ad8e-b173e7c9e94c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>field_id</th>\n",
              "      <th>crop_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>757</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>756</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1372</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1374</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1986</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-640cb9d4-6185-4545-ad8e-b173e7c9e94c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-640cb9d4-6185-4545-ad8e-b173e7c9e94c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-640cb9d4-6185-4545-ad8e-b173e7c9e94c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "field_crop_pair.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY7mbJBYKsYa",
        "outputId": "bc75a5e6-3d9e-4e72-ab1b-7a4c8f2cd1bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5551, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Our goal is developing a pixel-based Random Forest model. So we will create an X variable\n",
        "# such that, each row is a pixel and each column is one of the band observations mapped to its corresponding field. \n",
        "\n",
        "\n",
        "img_sh = 256\n",
        "n_selected_bands= len(selected_bands)\n",
        "\n",
        "n_obs = 1  #imagery per chip(no time series)\n",
        "\n",
        "def feature_extractor(data_ ,   path ):\n",
        "    '''\n",
        "        data_: Dataframe with 'field_paths' and 'unique_folder_id' columns\n",
        "        path: Path to source collections files\n",
        "\n",
        "        returns: pixel dataframe with corresponding field_ids\n",
        "        '''\n",
        "    \n",
        "    X = np.empty((0, n_selected_bands * n_obs))\n",
        "    X_tile = np.empty((img_sh * img_sh, 0))\n",
        "    X_arrays = []\n",
        "        \n",
        "    field_ids = np.empty((0, 1))\n",
        "\n",
        "    for idx, tile_id in tqdm(enumerate(data_['unique_folder_id'])):\n",
        "        \n",
        "        field_src =   rasterio.open( data_['field_paths'].values[idx])\n",
        "        field_array = field_src.read(1)\n",
        "        field_ids = np.append(field_ids, field_array.flatten())\n",
        "        \n",
        "        \n",
        "        bands_src = [rasterio.open(f'{main}/{path}/{path}_{tile_id}/{band}.tif') for band in selected_bands]\n",
        "        bands_array = [np.expand_dims(band.read(1).flatten(), axis=1) for band in bands_src]\n",
        "        \n",
        "        X_tile = np.hstack(bands_array)\n",
        "\n",
        "        X_arrays.append(X_tile)\n",
        "        \n",
        "\n",
        "    X = np.concatenate(X_arrays)\n",
        "    \n",
        "    data = pd.DataFrame(X, columns=selected_bands)\n",
        "\n",
        "    data['field_id'] = field_ids\n",
        "\n",
        "    return data[data['field_id']!=0]"
      ],
      "metadata": {
        "id": "szMEkOHLKt7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# competition_train_data.drop(1165, inplace=True)"
      ],
      "metadata": {
        "id": "VJ_rqLD4K7Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = feature_extractor(competition_train_data, source_collection)\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "spiiUZ01K9Di",
        "outputId": "5d7ddda6-7ae7-44d4-97eb-4c6acb95d1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1165it [03:44,  5.19it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       B01  B02  B03  B04  B05  B06  B07  B08  B8A  B09  B11  B12  field_id\n",
              "11031   43   39   38   38   41   54   63   61   64   12   57   37     757.0\n",
              "11287   43   39   38   38   42   57   67   63   72   12   63   42     757.0\n",
              "11288   43   39   38   37   41   59   69   65   78   12   68   43     757.0\n",
              "11289   43   38   37   36   41   59   69   64   78   12   68   43     757.0\n",
              "11543   43   39   38   38   42   57   67   64   72   12   63   42     757.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b567bdd-4c2f-4163-baba-de42e04b6839\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B01</th>\n",
              "      <th>B02</th>\n",
              "      <th>B03</th>\n",
              "      <th>B04</th>\n",
              "      <th>B05</th>\n",
              "      <th>B06</th>\n",
              "      <th>B07</th>\n",
              "      <th>B08</th>\n",
              "      <th>B8A</th>\n",
              "      <th>B09</th>\n",
              "      <th>B11</th>\n",
              "      <th>B12</th>\n",
              "      <th>field_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11031</th>\n",
              "      <td>43</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>41</td>\n",
              "      <td>54</td>\n",
              "      <td>63</td>\n",
              "      <td>61</td>\n",
              "      <td>64</td>\n",
              "      <td>12</td>\n",
              "      <td>57</td>\n",
              "      <td>37</td>\n",
              "      <td>757.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11287</th>\n",
              "      <td>43</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>42</td>\n",
              "      <td>57</td>\n",
              "      <td>67</td>\n",
              "      <td>63</td>\n",
              "      <td>72</td>\n",
              "      <td>12</td>\n",
              "      <td>63</td>\n",
              "      <td>42</td>\n",
              "      <td>757.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11288</th>\n",
              "      <td>43</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>41</td>\n",
              "      <td>59</td>\n",
              "      <td>69</td>\n",
              "      <td>65</td>\n",
              "      <td>78</td>\n",
              "      <td>12</td>\n",
              "      <td>68</td>\n",
              "      <td>43</td>\n",
              "      <td>757.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11289</th>\n",
              "      <td>43</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>36</td>\n",
              "      <td>41</td>\n",
              "      <td>59</td>\n",
              "      <td>69</td>\n",
              "      <td>64</td>\n",
              "      <td>78</td>\n",
              "      <td>12</td>\n",
              "      <td>68</td>\n",
              "      <td>43</td>\n",
              "      <td>757.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11543</th>\n",
              "      <td>43</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>42</td>\n",
              "      <td>57</td>\n",
              "      <td>67</td>\n",
              "      <td>64</td>\n",
              "      <td>72</td>\n",
              "      <td>12</td>\n",
              "      <td>63</td>\n",
              "      <td>42</td>\n",
              "      <td>757.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b567bdd-4c2f-4163-baba-de42e04b6839')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b567bdd-4c2f-4163-baba-de42e04b6839 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b567bdd-4c2f-4163-baba-de42e04b6839');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The following are the derived indices:\n",
        "\n",
        "# NDVI (Normalized Green Red Difference Index) : (B08 - B04)/ (B08 + B04)\n",
        "# GLI (Green Leaf Index) : (2 * B03 - B04 - B02)/(2 * B03 + B04 + B02)\n",
        "# CVI : (Chlorophyll Vegetation Index) : (B08 / B03) * (B04 / B03)\n",
        "# SIPI : (B08 - B02) / (B08 - B04)\n",
        "# S2REP : 705 + 35 * (((( B07 + B04 ) / 2) - B05 ) / (B06 - B05))\n",
        "# CCCI : ((B08 - B05) / (B08 + B05)) / ((B08 - B04) / (B08 + B04))\n",
        "# HUE (Overall Hue Index) : atan( 2 * ( B02 - B03 - B04 ) / 30.5 * ( B03 - B04 ))\n",
        "# RENDVI : (B06 - B05) / (B06 + B05)\n",
        "# RECI (Chlorophyll Index) : ( B08 / B04 ) - 1\n",
        "# EVI (Enhanced Vegetation Index) : (2.5 * (B08 - B04) / ((B08 + 6.0 * B04 - 7.5 * B02) + 1.0))\n",
        "# EVI2 (Enhanced Vegetation Index 2) : (2.4 * (B08 - B04) / (B08 + B04 + 1.0))\n",
        "# NDWI : (B04 - B02) / (B04 + B02)\n",
        "# NPCRI : (B03 - B08) / (B03 + B08)"
      ],
      "metadata": {
        "id": "7kHCUU8TK_DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "#add pre-processing features:\n",
        "def add_preprocessing_features(train_data):\n",
        "  train_data[\"NDVI\"] = (train_data[\"B08\"]-train_data[\"B04\"]) / (train_data[\"B08\"] + train_data[\"B04\"])\n",
        "  train_data[\"GLI\"] = (2 * train_data.B03 - train_data.B04 - train_data.B02)/(2 * train_data.B03 + train_data.B04 + train_data.B02)\n",
        "  train_data[\"CVI\"] =  (train_data.B08 / train_data.B03) * (train_data.B04 / train_data.B03)\n",
        "  train_data[\"SIPI\"] = (train_data.B08 - train_data.B02) / (train_data.B08 - train_data.B04)\n",
        "  train_data[\"S2REP\"] = 705 + 35 * (((( train_data.B07 + train_data.B04 ) / 2) - train_data.B05 ) / (train_data.B06 - train_data.B05))\n",
        "  train_data[\"CCCI\"] = ((train_data.B08 - train_data.B05) / (train_data.B08 + train_data.B05)) / ((train_data.B08 - train_data.B04) / (train_data.B08 + train_data.B04))\n",
        "  train_data[\"HUE\"] = np.arctan( 2 * ( train_data.B02 - train_data.B03 - train_data.B04 ) / 30.5 * ( train_data.B03 - train_data.B04 ))\n",
        "  train_data[\"RENDVI\"] = (train_data.B06 - train_data.B05) / (train_data.B06 + train_data.B05)\n",
        "  train_data[\"RECI\"] = ( train_data.B08 / train_data.B04 ) - 1\n",
        "  train_data[\"EVI\"] = (2.5 * (train_data.B08 - train_data.B04) / ((train_data.B08 + 6.0 * train_data.B04 - 7.5 * train_data.B02) + 1.0))\n",
        "  train_data[\"EVI2\"] = (2.4 * (train_data.B08 - train_data.B04) / (train_data.B08 + train_data.B04 + 1.0))\n",
        "  train_data[\"NDWI\"] = (train_data.B04 - train_data.B02) / (train_data.B04 + train_data.B02)\n",
        "  train_data[\"NPCRI\"] = (train_data.B03 - train_data.B08) / (train_data.B03 + train_data.B08)\n",
        "\n",
        "  #fille nan with mean:\n",
        "  S2REP = train_data.S2REP.mean()\n",
        "  EVI = train_data.EVI.mean()\n",
        "\n",
        "  train_data.S2REP.fillna(value=S2REP, inplace=True)\n",
        "  train_data.EVI.fillna(value=EVI, inplace=True)\n",
        "  train_data.replace([np.nan], 0, inplace=True)\n",
        "  train_data.dropna(inplace=True)\n",
        "\n",
        "  #replace inf with max 0:\n",
        "  train_data.replace([np.inf, -np.inf], 0, inplace=True)\n",
        "\n",
        "add_preprocessing_features(train_data)\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "hxrMRNxjLAji",
        "outputId": "5e919749-3361-45a7-971e-72bad2a9476e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       B01  B02  B03  B04  B05  B06  B07  B08  B8A  B09  ...      SIPI  \\\n",
              "11031   43   39   38   38   41   54   63   61   64   12  ...  0.956522   \n",
              "11287   43   39   38   38   42   57   67   63   72   12  ...  0.960000   \n",
              "11288   43   39   38   37   41   59   69   65   78   12  ...  0.928571   \n",
              "11289   43   38   37   36   41   59   69   64   78   12  ...  0.928571   \n",
              "11543   43   39   38   38   42   57   67   64   72   12  ...  0.961538   \n",
              "\n",
              "            S2REP      CCCI       HUE    RENDVI      RECI         EVI  \\\n",
              "11031  730.576923  0.843990  0.000000  0.136842  0.605263  -23.000000   \n",
              "11287  729.500000  0.808000  0.000000  0.151515  0.657895 -125.000000   \n",
              "11288  728.333333  0.824798  1.406529  0.180000  0.756757  -15.555556   \n",
              "11289  727.361111  0.782313  1.408264  0.180000  0.777778  -17.500000   \n",
              "11543  729.500000  0.814224  0.000000  0.151515  0.684211  130.000000   \n",
              "\n",
              "           EVI2      NDWI     NPCRI  \n",
              "11031  0.552000  3.311688  2.353535  \n",
              "11287  0.588235  3.311688  2.287129  \n",
              "11288  0.652427  3.342105  2.223301  \n",
              "11289  0.665347  3.432432  2.267327  \n",
              "11543  0.605825  3.311688  2.254902  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7dd087d-9d5f-4fb4-9a44-58a90ede6a75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B01</th>\n",
              "      <th>B02</th>\n",
              "      <th>B03</th>\n",
              "      <th>B04</th>\n",
              "      <th>B05</th>\n",
              "      <th>B06</th>\n",
              "      <th>B07</th>\n",
              "      <th>B08</th>\n",
              "      <th>B8A</th>\n",
              "      <th>B09</th>\n",
              "      <th>...</th>\n",
              "      <th>SIPI</th>\n",
              "      <th>S2REP</th>\n",
              "      <th>CCCI</th>\n",
              "      <th>HUE</th>\n",
              "      <th>RENDVI</th>\n",
              "      <th>RECI</th>\n",
              "      <th>EVI</th>\n",
              "      <th>EVI2</th>\n",
              "      <th>NDWI</th>\n",
              "      <th>NPCRI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11031</th>\n",
              "      <td>43</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>41</td>\n",
              "      <td>54</td>\n",
              "      <td>63</td>\n",
              "      <td>61</td>\n",
              "      <td>64</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>730.576923</td>\n",
              "      <td>0.843990</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.136842</td>\n",
              "      <td>0.605263</td>\n",
              "      <td>-23.000000</td>\n",
              "      <td>0.552000</td>\n",
              "      <td>3.311688</td>\n",
              "      <td>2.353535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11287</th>\n",
              "      <td>43</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>42</td>\n",
              "      <td>57</td>\n",
              "      <td>67</td>\n",
              "      <td>63</td>\n",
              "      <td>72</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>729.500000</td>\n",
              "      <td>0.808000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151515</td>\n",
              "      <td>0.657895</td>\n",
              "      <td>-125.000000</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>3.311688</td>\n",
              "      <td>2.287129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11288</th>\n",
              "      <td>43</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>41</td>\n",
              "      <td>59</td>\n",
              "      <td>69</td>\n",
              "      <td>65</td>\n",
              "      <td>78</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>728.333333</td>\n",
              "      <td>0.824798</td>\n",
              "      <td>1.406529</td>\n",
              "      <td>0.180000</td>\n",
              "      <td>0.756757</td>\n",
              "      <td>-15.555556</td>\n",
              "      <td>0.652427</td>\n",
              "      <td>3.342105</td>\n",
              "      <td>2.223301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11289</th>\n",
              "      <td>43</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>36</td>\n",
              "      <td>41</td>\n",
              "      <td>59</td>\n",
              "      <td>69</td>\n",
              "      <td>64</td>\n",
              "      <td>78</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.928571</td>\n",
              "      <td>727.361111</td>\n",
              "      <td>0.782313</td>\n",
              "      <td>1.408264</td>\n",
              "      <td>0.180000</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>-17.500000</td>\n",
              "      <td>0.665347</td>\n",
              "      <td>3.432432</td>\n",
              "      <td>2.267327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11543</th>\n",
              "      <td>43</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "      <td>38</td>\n",
              "      <td>42</td>\n",
              "      <td>57</td>\n",
              "      <td>67</td>\n",
              "      <td>64</td>\n",
              "      <td>72</td>\n",
              "      <td>12</td>\n",
              "      <td>...</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>729.500000</td>\n",
              "      <td>0.814224</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151515</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.605825</td>\n",
              "      <td>3.311688</td>\n",
              "      <td>2.254902</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7dd087d-9d5f-4fb4-9a44-58a90ede6a75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7dd087d-9d5f-4fb4-9a44-58a90ede6a75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7dd087d-9d5f-4fb4-9a44-58a90ede6a75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def get_dataset(df, field_crop_pair, stats='mean'):\n",
        "  dataset_df = None\n",
        "\n",
        "  if stats=='mean':\n",
        "    dataset_df = df.groupby(['field_id']).mean().reset_index()\n",
        "    dataset_df.field_id = [str(int(i)) for i in dataset_df.field_id.values]\n",
        "  elif stats=='median':\n",
        "    dataset_df = df.groupby(['field_id']).median().reset_index()\n",
        "    dataset_df.field_id = [str(int(i)) for i in dataset_df.field_id.values]\n",
        "  elif stats=='std':\n",
        "    dataset_df = df.groupby(['field_id']).std().reset_index()\n",
        "    dataset_df.field_id = [str(int(i)) for i in dataset_df.field_id.values]\n",
        "  elif stats=='variance':\n",
        "    dataset_df = df.groupby(['field_id']).var().reset_index()\n",
        "    dataset_df.field_id = [str(int(i)) for i in dataset_df.field_id.values]\n",
        "  elif stats=='min':\n",
        "    dataset_df = df.groupby(['field_id']).min().reset_index()\n",
        "    dataset_df.field_id = [str(int(i)) for i in dataset_df.field_id.values]\n",
        "  elif stats=='max':\n",
        "    dataset_df = df.groupby(['field_id']).max().reset_index()\n",
        "    dataset_df.field_id = [str(int(i)) for i in dataset_df.field_id.values]\n",
        "  elif stats=='mode':\n",
        "    dataset_df = df.groupby(['field_id']).agg(lambda x:x.value_counts().index[0]).reset_index()\n",
        "    dataset_df.field_id = [str(int(i)) for i in dataset_df.field_id.values]\n",
        "  elif stats=='skew':\n",
        "    dataset_df = df.groupby(['field_id']).skew().reset_index()\n",
        "    dataset_df.field_id = [str(int(i)) for i in dataset_df.field_id.values]\n",
        "  elif stats=='kurt':\n",
        "    dataset_df = df.groupby(['field_id']).agg(pd.Series.kurt).reset_index()\n",
        "    dataset_df.field_id = [str(int(i)) for i in dataset_df.field_id.values]\n",
        "  \n",
        "  if not isinstance(field_crop_pair, type(None)):\n",
        "    train_df = pd.merge(dataset_df, field_crop_pair , on='field_id' )\n",
        "  else : train_df = dataset_df\n",
        "\n",
        "  #check for NaN:\n",
        "  train_df.replace([np.nan], 0, inplace=True)\n",
        "\n",
        "  return train_df\n",
        "\n",
        "def get_dataset_np(dataset_df, label_col='crop_id', label_encoder=True):\n",
        "  x = dataset_df.drop([label_col, 'field_id'], axis=1) if label_col in dataset_df.columns else dataset_df.drop(\"field_id\", axis=1)\n",
        "  y = dataset_df[label_col] if label_col in dataset_df.columns else None\n",
        "\n",
        "  if label_encoder and  not isinstance(y, type(None)):\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "  return x,y.astype(int) if not isinstance(y, type(None)) else None"
      ],
      "metadata": {
        "id": "0l3GkqBfLCdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats = ['mean', 'median', 'std', 'min', 'max', 'mode', 'skew', 'kurt']\n",
        "datasets = [get_dataset(train_data, field_crop_pair, stat) for stat in stats]\n",
        "\n",
        "#Prepare datasets:\n",
        "datasets = [get_dataset_np(ds) for ds in datasets]\n",
        "\n",
        "# Perform train-test split for each dataset\n",
        "train_test_splits = [train_test_split(X, y, test_size=0.2, random_state=42) for X, y in datasets]\n",
        "X_train_list, X_test_list, y_train_list, y_test_list = zip(*train_test_splits)"
      ],
      "metadata": {
        "id": "daU-ZwfXLcQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training:"
      ],
      "metadata": {
        "id": "frSsZYe4Lq3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 1234"
      ],
      "metadata": {
        "id": "jwusuOY0AJCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#this model allows a combination of multiple sklearn models to be trained on uniques datasets:\n",
        "class ModelEnsemble(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, models):\n",
        "        self.models = models\n",
        "        self.weights = None\n",
        "\n",
        "    #takes a list of qunique dataset per model:\n",
        "    def fit(self, X_list, y_list):\n",
        "        for model, X, y in zip(self.models, X_list, y_list):\n",
        "            model.fit(X, y)\n",
        "\n",
        "    def predict(self, X_list):\n",
        "        predictions = np.array([model.predict(X) for model, X in zip(self.models, X_list)])\n",
        "        ensemble_predictions = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=0, arr=predictions)\n",
        "        return ensemble_predictions\n",
        "\n",
        "    def predict_prob(self, X_list):\n",
        "        prob_list = np.array([model.predict_proba(X) for model, X in zip(self.models, X_list)])\n",
        "        if self.weights is not None:\n",
        "            prob_list = prob_list * np.array(self.weights)[:, np.newaxis, np.newaxis]\n",
        "        ensemble_prob = prob_list.sum(axis=0) / prob_list.sum(axis=0).sum(axis=1, keepdims=True)\n",
        "        return ensemble_prob\n",
        "\n",
        "    #define each model wight/contribution of the final prediction score based on its f1 score:\n",
        "    def calculate_weights(self, X_test_list, y_test):\n",
        "        f1_scores = np.array([f1_score(y_test, model.predict(X_test), average='weighted') for model, X_test in zip(self.models, X_test_list)])\n",
        "        self.weights = f1_scores / f1_scores.sum()\n",
        "\n",
        "    def model_f1_scores(self, X_test_list, y_test):\n",
        "        f1_scores = np.array([f1_score(y_test, model.predict(X_test), average='weighted') for model, X_test in zip(self.models, X_test_list)])\n",
        "        return f1_scores"
      ],
      "metadata": {
        "id": "SxdeUQ06Lyt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forests Model ensemble:"
      ],
      "metadata": {
        "id": "L-jy3OM3LuWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import clone\n",
        "\n",
        "foundation_model = RandomForestClassifier(n_estimators = 20, random_state = 0, n_jobs = 3)\n",
        "\n",
        "#train multiple random forest models:\n",
        "models = [clone(foundation_model) for i in range(len(datasets))]\n",
        "\n",
        "# Create an ensemble of the RandomForest models\n",
        "model = ModelEnsemble(models=models)\n",
        "model_type = 'ensemble'\n",
        "\n",
        "# Fit the ensemble model\n",
        "model.fit(X_train_list, y_train_list)\n",
        "\n",
        "# Calculate weights based on F1 scores\n",
        "model.calculate_weights(X_test_list, y_test_list[0])\n",
        "print(\"weights : \",model.weights)\n",
        "\n",
        "#show indivisual model performence:\n",
        "print(\"Indivisual model performence : \", model.model_f1_scores(X_test_list,y_test_list[0]))\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test_list)\n",
        "print(\"Ensemble accuracy:\", accuracy_score(y_test_list[0], predictions))\n",
        "\n",
        "# Get class probabilities\n",
        "probabilities = model.predict_prob(X_test_list)\n",
        "print(\"Ensemble probabilities:\\n\", probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "i3bPaz8LL5Va",
        "outputId": "edf6965a-532a-4e60-f97e-3a2362269c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ab8b888ff3ca>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Fit the ensemble model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Calculate weights based on F1 scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-91684f26cf99>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_list, y_list)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost Model Ensemble:"
      ],
      "metadata": {
        "id": "aiEoBJkEMlVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import clone\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "foundation_model = XGBClassifier(eta= 0.05, max_depth= 5, objective= \"multi:softprob\", num_class=13, n_estimators=400, learning_rate= 0.1)\n",
        "\n",
        "#train multiple random forest models:\n",
        "models = [clone(foundation_model) for i in range(len(datasets))]\n",
        "\n",
        "# Create an ensemble of the RandomForest models\n",
        "model = ModelEnsemble(models=models)\n",
        "model_type = 'ensemble'\n",
        "\n",
        "# Fit the ensemble model\n",
        "model.fit(X_train_list, y_train_list)\n",
        "\n",
        "# Calculate weights based on F1 scores\n",
        "model.calculate_weights(X_test_list, y_test_list[0])\n",
        "print(\"weights : \",model.weights)\n",
        "\n",
        "#show indivisual model performence:\n",
        "print(\"Indivisual model performence : \", model.model_f1_scores(X_test_list,y_test_list[0]))\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test_list)\n",
        "print(\"Ensemble accuracy:\", accuracy_score(y_test_list[0], predictions))\n",
        "\n",
        "# Get class probabilities\n",
        "probabilities = model.predict_prob(X_test_list)\n",
        "print(\"Ensemble probabilities:\\n\", probabilities)"
      ],
      "metadata": {
        "id": "vk0PSBYcMom6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neural Network Model Ensemble:"
      ],
      "metadata": {
        "id": "watVxunTMt3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import clone\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "#define a foundation model to be cloned and used as a start point by all models in the ensemble:\n",
        "foundation_model = MLPClassifier(hidden_layer_sizes=(256,128,64,32), activation='relu', solver='adam', max_iter=200, learning_rate_init=0.01, early_stopping=False , verbose=True, random_state=random_state)\n",
        "\n",
        "#train multiple random forest models:\n",
        "models = [clone(foundation_model) for i in range(len(datasets))]\n",
        "\n",
        "# Create an ensemble of the RandomForest models\n",
        "model = ModelEnsemble(models=models)\n",
        "model_type = 'ensemble'\n",
        "\n",
        "# Fit the ensemble model\n",
        "model.fit(X_train_list, y_train_list)\n",
        "\n",
        "# Calculate weights based on F1 scores\n",
        "model.calculate_weights(X_test_list, y_test_list[0])\n",
        "print(\"weights : \",model.weights)\n",
        "\n",
        "#show indivisual model performence:\n",
        "print(\"Indivisual model performence : \", model.model_f1_scores(X_test_list,y_test_list[0]))\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test_list)\n",
        "print(\"Ensemble accuracy:\", accuracy_score(y_test_list[0], predictions))\n",
        "\n",
        "# Get class probabilities\n",
        "probabilities = model.predict_prob(X_test_list)\n",
        "print(\"Ensemble probabilities:\\n\", probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A4MeQIeM_QM",
        "outputId": "6d1ad342-be04-4174-eeef-35be321f5ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 11.40332129\n",
            "Iteration 2, loss = 1.89449359\n",
            "Iteration 3, loss = 1.67269075\n",
            "Iteration 4, loss = 1.65130135\n",
            "Iteration 5, loss = 1.64879586\n",
            "Iteration 6, loss = 1.63237996\n",
            "Iteration 7, loss = 1.58243207\n",
            "Iteration 8, loss = 1.54733337\n",
            "Iteration 9, loss = 1.53390050\n",
            "Iteration 10, loss = 1.52198405\n",
            "Iteration 11, loss = 1.51290923\n",
            "Iteration 12, loss = 1.54199123\n",
            "Iteration 13, loss = 1.51237127\n",
            "Iteration 14, loss = 1.49815334\n",
            "Iteration 15, loss = 1.48478364\n",
            "Iteration 16, loss = 1.50132050\n",
            "Iteration 17, loss = 1.47757940\n",
            "Iteration 18, loss = 1.46437787\n",
            "Iteration 19, loss = 1.44893579\n",
            "Iteration 20, loss = 1.42451913\n",
            "Iteration 21, loss = 1.39989042\n",
            "Iteration 22, loss = 1.41905747\n",
            "Iteration 23, loss = 1.39199061\n",
            "Iteration 24, loss = 1.39840420\n",
            "Iteration 25, loss = 1.35125386\n",
            "Iteration 26, loss = 1.32629526\n",
            "Iteration 27, loss = 1.32155045\n",
            "Iteration 28, loss = 1.31538084\n",
            "Iteration 29, loss = 1.31187335\n",
            "Iteration 30, loss = 1.28881461\n",
            "Iteration 31, loss = 1.25209150\n",
            "Iteration 32, loss = 1.28043087\n",
            "Iteration 33, loss = 1.25482454\n",
            "Iteration 34, loss = 1.23909188\n",
            "Iteration 35, loss = 1.21544475\n",
            "Iteration 36, loss = 1.20081357\n",
            "Iteration 37, loss = 1.19020072\n",
            "Iteration 38, loss = 1.20332063\n",
            "Iteration 39, loss = 1.22638966\n",
            "Iteration 40, loss = 1.20322769\n",
            "Iteration 41, loss = 1.20082949\n",
            "Iteration 42, loss = 1.19212926\n",
            "Iteration 43, loss = 1.17452137\n",
            "Iteration 44, loss = 1.18168308\n",
            "Iteration 45, loss = 1.19974032\n",
            "Iteration 46, loss = 1.17697950\n",
            "Iteration 47, loss = 1.17109950\n",
            "Iteration 48, loss = 1.18332407\n",
            "Iteration 49, loss = 1.20411427\n",
            "Iteration 50, loss = 1.18245578\n",
            "Iteration 51, loss = 1.16430744\n",
            "Iteration 52, loss = 1.16364402\n",
            "Iteration 53, loss = 1.16239853\n",
            "Iteration 54, loss = 1.16917777\n",
            "Iteration 55, loss = 1.16433756\n",
            "Iteration 56, loss = 1.16959618\n",
            "Iteration 57, loss = 1.16546320\n",
            "Iteration 58, loss = 1.14820246\n",
            "Iteration 59, loss = 1.16503593\n",
            "Iteration 60, loss = 1.18111797\n",
            "Iteration 61, loss = 1.13782558\n",
            "Iteration 62, loss = 1.15379422\n",
            "Iteration 63, loss = 1.13668902\n",
            "Iteration 64, loss = 1.13453000\n",
            "Iteration 65, loss = 1.14979256\n",
            "Iteration 66, loss = 1.13518534\n",
            "Iteration 67, loss = 1.12747810\n",
            "Iteration 68, loss = 1.12507934\n",
            "Iteration 69, loss = 1.15238380\n",
            "Iteration 70, loss = 1.24678846\n",
            "Iteration 71, loss = 1.16170509\n",
            "Iteration 72, loss = 1.13624103\n",
            "Iteration 73, loss = 1.13424018\n",
            "Iteration 74, loss = 1.11922743\n",
            "Iteration 75, loss = 1.11346602\n",
            "Iteration 76, loss = 1.11162332\n",
            "Iteration 77, loss = 1.11800019\n",
            "Iteration 78, loss = 1.10679611\n",
            "Iteration 79, loss = 1.11916768\n",
            "Iteration 80, loss = 1.12761755\n",
            "Iteration 81, loss = 1.12148667\n",
            "Iteration 82, loss = 1.15354332\n",
            "Iteration 83, loss = 1.14138915\n",
            "Iteration 84, loss = 1.14351120\n",
            "Iteration 85, loss = 1.11160040\n",
            "Iteration 86, loss = 1.13180867\n",
            "Iteration 87, loss = 1.18796470\n",
            "Iteration 88, loss = 1.12429283\n",
            "Iteration 89, loss = 1.14584083\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 10.98384400\n",
            "Iteration 2, loss = 1.78983553\n",
            "Iteration 3, loss = 1.66213498\n",
            "Iteration 4, loss = 1.57381630\n",
            "Iteration 5, loss = 1.52989402\n",
            "Iteration 6, loss = 1.48888647\n",
            "Iteration 7, loss = 1.52708862\n",
            "Iteration 8, loss = 1.44387208\n",
            "Iteration 9, loss = 1.42879496\n",
            "Iteration 10, loss = 1.35658015\n",
            "Iteration 11, loss = 1.31584758\n",
            "Iteration 12, loss = 1.32740460\n",
            "Iteration 13, loss = 1.26640733\n",
            "Iteration 14, loss = 1.28221857\n",
            "Iteration 15, loss = 1.29814594\n",
            "Iteration 16, loss = 1.23581394\n",
            "Iteration 17, loss = 1.21300711\n",
            "Iteration 18, loss = 1.30263745\n",
            "Iteration 19, loss = 1.22621370\n",
            "Iteration 20, loss = 1.23441000\n",
            "Iteration 21, loss = 1.46401036\n",
            "Iteration 22, loss = 1.33823371\n",
            "Iteration 23, loss = 1.24216583\n",
            "Iteration 24, loss = 1.21148013\n",
            "Iteration 25, loss = 1.20218111\n",
            "Iteration 26, loss = 1.19508403\n",
            "Iteration 27, loss = 1.18052868\n",
            "Iteration 28, loss = 1.17792528\n",
            "Iteration 29, loss = 1.18881913\n",
            "Iteration 30, loss = 1.19136083\n",
            "Iteration 31, loss = 1.16091068\n",
            "Iteration 32, loss = 1.16816847\n",
            "Iteration 33, loss = 1.20212854\n",
            "Iteration 34, loss = 1.19114184\n",
            "Iteration 35, loss = 1.16622057\n",
            "Iteration 36, loss = 1.15819438\n",
            "Iteration 37, loss = 1.17079422\n",
            "Iteration 38, loss = 1.17430285\n",
            "Iteration 39, loss = 1.19316191\n",
            "Iteration 40, loss = 1.19659713\n",
            "Iteration 41, loss = 1.16215635\n",
            "Iteration 42, loss = 1.20107189\n",
            "Iteration 43, loss = 1.19408375\n",
            "Iteration 44, loss = 1.15610336\n",
            "Iteration 45, loss = 1.15074637\n",
            "Iteration 46, loss = 1.13840375\n",
            "Iteration 47, loss = 1.13697193\n",
            "Iteration 48, loss = 1.15579451\n",
            "Iteration 49, loss = 1.15439037\n",
            "Iteration 50, loss = 1.14881415\n",
            "Iteration 51, loss = 1.14606030\n",
            "Iteration 52, loss = 1.14886727\n",
            "Iteration 53, loss = 1.14202222\n",
            "Iteration 54, loss = 1.13195444\n",
            "Iteration 55, loss = 1.18927447\n",
            "Iteration 56, loss = 1.17262598\n",
            "Iteration 57, loss = 1.14952585\n",
            "Iteration 58, loss = 1.14402258\n",
            "Iteration 59, loss = 1.14767993\n",
            "Iteration 60, loss = 1.12596438\n",
            "Iteration 61, loss = 1.14262908\n",
            "Iteration 62, loss = 1.16421342\n",
            "Iteration 63, loss = 1.12226489\n",
            "Iteration 64, loss = 1.13081304\n",
            "Iteration 65, loss = 1.14477593\n",
            "Iteration 66, loss = 1.11391444\n",
            "Iteration 67, loss = 1.11482703\n",
            "Iteration 68, loss = 1.10637085\n",
            "Iteration 69, loss = 1.16661065\n",
            "Iteration 70, loss = 1.14798226\n",
            "Iteration 71, loss = 1.11370787\n",
            "Iteration 72, loss = 1.10141799\n",
            "Iteration 73, loss = 1.10443913\n",
            "Iteration 74, loss = 1.11237262\n",
            "Iteration 75, loss = 1.12045100\n",
            "Iteration 76, loss = 1.10277887\n",
            "Iteration 77, loss = 1.10783450\n",
            "Iteration 78, loss = 1.13199132\n",
            "Iteration 79, loss = 1.11786405\n",
            "Iteration 80, loss = 1.13778903\n",
            "Iteration 81, loss = 1.14130051\n",
            "Iteration 82, loss = 1.12471761\n",
            "Iteration 83, loss = 1.23090990\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1.79189535\n",
            "Iteration 2, loss = 1.45513368\n",
            "Iteration 3, loss = 1.38383499\n",
            "Iteration 4, loss = 1.35364947\n",
            "Iteration 5, loss = 1.33477146\n",
            "Iteration 6, loss = 1.30600485\n",
            "Iteration 7, loss = 1.33694102\n",
            "Iteration 8, loss = 1.30260042\n",
            "Iteration 9, loss = 1.27679220\n",
            "Iteration 10, loss = 1.28072584\n",
            "Iteration 11, loss = 1.24696793\n",
            "Iteration 12, loss = 1.25030691\n",
            "Iteration 13, loss = 1.25756908\n",
            "Iteration 14, loss = 1.27169760\n",
            "Iteration 15, loss = 1.22735300\n",
            "Iteration 16, loss = 1.21243614\n",
            "Iteration 17, loss = 1.20922572\n",
            "Iteration 18, loss = 1.21708722\n",
            "Iteration 19, loss = 1.21069222\n",
            "Iteration 20, loss = 1.19461291\n",
            "Iteration 21, loss = 1.19472566\n",
            "Iteration 22, loss = 1.17614478\n",
            "Iteration 23, loss = 1.18617407\n",
            "Iteration 24, loss = 1.19634213\n",
            "Iteration 25, loss = 1.16488774\n",
            "Iteration 26, loss = 1.17318654\n",
            "Iteration 27, loss = 1.17081224\n",
            "Iteration 28, loss = 1.16510027\n",
            "Iteration 29, loss = 1.15751405\n",
            "Iteration 30, loss = 1.15308643\n",
            "Iteration 31, loss = 1.12195321\n",
            "Iteration 32, loss = 1.11494450\n",
            "Iteration 33, loss = 1.11325615\n",
            "Iteration 34, loss = 1.11547795\n",
            "Iteration 35, loss = 1.10265541\n",
            "Iteration 36, loss = 1.11577440\n",
            "Iteration 37, loss = 1.10084497\n",
            "Iteration 38, loss = 1.09505408\n",
            "Iteration 39, loss = 1.08175660\n",
            "Iteration 40, loss = 1.10492429\n",
            "Iteration 41, loss = 1.11395849\n",
            "Iteration 42, loss = 1.07056031\n",
            "Iteration 43, loss = 1.06924478\n",
            "Iteration 44, loss = 1.08778545\n",
            "Iteration 45, loss = 1.09999128\n",
            "Iteration 46, loss = 1.07093259\n",
            "Iteration 47, loss = 1.04084636\n",
            "Iteration 48, loss = 1.07271439\n",
            "Iteration 49, loss = 1.03397541\n",
            "Iteration 50, loss = 1.04896365\n",
            "Iteration 51, loss = 1.05397454\n",
            "Iteration 52, loss = 1.01276043\n",
            "Iteration 53, loss = 1.01315678\n",
            "Iteration 54, loss = 1.02344412\n",
            "Iteration 55, loss = 1.01797955\n",
            "Iteration 56, loss = 1.03558308\n",
            "Iteration 57, loss = 1.02461714\n",
            "Iteration 58, loss = 0.99976711\n",
            "Iteration 59, loss = 1.00445254\n",
            "Iteration 60, loss = 0.98473846\n",
            "Iteration 61, loss = 0.95091369\n",
            "Iteration 62, loss = 0.99178403\n",
            "Iteration 63, loss = 0.97613523\n",
            "Iteration 64, loss = 0.94972006\n",
            "Iteration 65, loss = 1.00559508\n",
            "Iteration 66, loss = 0.98319221\n",
            "Iteration 67, loss = 0.95960575\n",
            "Iteration 68, loss = 0.94484653\n",
            "Iteration 69, loss = 0.94678722\n",
            "Iteration 70, loss = 0.94034174\n",
            "Iteration 71, loss = 0.96742674\n",
            "Iteration 72, loss = 0.96465767\n",
            "Iteration 73, loss = 0.94788195\n",
            "Iteration 74, loss = 0.93853671\n",
            "Iteration 75, loss = 0.92126580\n",
            "Iteration 76, loss = 0.92260870\n",
            "Iteration 77, loss = 0.90767597\n",
            "Iteration 78, loss = 0.95503397\n",
            "Iteration 79, loss = 0.91615705\n",
            "Iteration 80, loss = 0.88322887\n",
            "Iteration 81, loss = 0.90121049\n",
            "Iteration 82, loss = 0.92617869\n",
            "Iteration 83, loss = 0.93642587\n",
            "Iteration 84, loss = 0.94980318\n",
            "Iteration 85, loss = 0.91042723\n",
            "Iteration 86, loss = 0.87351936\n",
            "Iteration 87, loss = 0.91567222\n",
            "Iteration 88, loss = 0.90293765\n",
            "Iteration 89, loss = 0.90635521\n",
            "Iteration 90, loss = 0.90545613\n",
            "Iteration 91, loss = 0.88136691\n",
            "Iteration 92, loss = 0.88526308\n",
            "Iteration 93, loss = 0.87270519\n",
            "Iteration 94, loss = 0.83737488\n",
            "Iteration 95, loss = 0.89601639\n",
            "Iteration 96, loss = 0.87071480\n",
            "Iteration 97, loss = 0.87492345\n",
            "Iteration 98, loss = 0.85898375\n",
            "Iteration 99, loss = 0.88146905\n",
            "Iteration 100, loss = 0.85373055\n",
            "Iteration 101, loss = 0.85661019\n",
            "Iteration 102, loss = 0.83172017\n",
            "Iteration 103, loss = 0.83832815\n",
            "Iteration 104, loss = 0.82949391\n",
            "Iteration 105, loss = 0.88150421\n",
            "Iteration 106, loss = 0.79159692\n",
            "Iteration 107, loss = 0.82497932\n",
            "Iteration 108, loss = 0.82114021\n",
            "Iteration 109, loss = 0.78660952\n",
            "Iteration 110, loss = 0.80289090\n",
            "Iteration 111, loss = 0.81844407\n",
            "Iteration 112, loss = 0.83595509\n",
            "Iteration 113, loss = 0.84567386\n",
            "Iteration 114, loss = 0.83607053\n",
            "Iteration 115, loss = 0.82811690\n",
            "Iteration 116, loss = 0.83686493\n",
            "Iteration 117, loss = 0.83114482\n",
            "Iteration 118, loss = 0.79323505\n",
            "Iteration 119, loss = 0.85885901\n",
            "Iteration 120, loss = 0.83336708\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 16.25408905\n",
            "Iteration 2, loss = 1.83956350\n",
            "Iteration 3, loss = 1.62116142\n",
            "Iteration 4, loss = 1.56236340\n",
            "Iteration 5, loss = 1.51766521\n",
            "Iteration 6, loss = 1.46145539\n",
            "Iteration 7, loss = 1.53476498\n",
            "Iteration 8, loss = 1.40159270\n",
            "Iteration 9, loss = 1.35136440\n",
            "Iteration 10, loss = 1.31253022\n",
            "Iteration 11, loss = 1.39012715\n",
            "Iteration 12, loss = 1.31106335\n",
            "Iteration 13, loss = 1.28949992\n",
            "Iteration 14, loss = 1.33041301\n",
            "Iteration 15, loss = 1.26253929\n",
            "Iteration 16, loss = 1.27649920\n",
            "Iteration 17, loss = 1.23353208\n",
            "Iteration 18, loss = 1.24138821\n",
            "Iteration 19, loss = 1.24016661\n",
            "Iteration 20, loss = 1.22663736\n",
            "Iteration 21, loss = 1.26252845\n",
            "Iteration 22, loss = 1.22944404\n",
            "Iteration 23, loss = 1.20294305\n",
            "Iteration 24, loss = 1.19118790\n",
            "Iteration 25, loss = 1.24077056\n",
            "Iteration 26, loss = 1.20991874\n",
            "Iteration 27, loss = 1.20696720\n",
            "Iteration 28, loss = 1.21157561\n",
            "Iteration 29, loss = 1.21465420\n",
            "Iteration 30, loss = 1.20752053\n",
            "Iteration 31, loss = 1.18722691\n",
            "Iteration 32, loss = 1.17832511\n",
            "Iteration 33, loss = 1.17928515\n",
            "Iteration 34, loss = 1.16756387\n",
            "Iteration 35, loss = 1.16915243\n",
            "Iteration 36, loss = 1.19802251\n",
            "Iteration 37, loss = 1.16479930\n",
            "Iteration 38, loss = 1.20660439\n",
            "Iteration 39, loss = 1.17999449\n",
            "Iteration 40, loss = 1.15434576\n",
            "Iteration 41, loss = 1.16495447\n",
            "Iteration 42, loss = 1.15920491\n",
            "Iteration 43, loss = 1.15364302\n",
            "Iteration 44, loss = 1.16958727\n",
            "Iteration 45, loss = 1.18051185\n",
            "Iteration 46, loss = 1.15418496\n",
            "Iteration 47, loss = 1.16436808\n",
            "Iteration 48, loss = 1.16533266\n",
            "Iteration 49, loss = 1.25142522\n",
            "Iteration 50, loss = 1.20055921\n",
            "Iteration 51, loss = 1.15181407\n",
            "Iteration 52, loss = 1.16232442\n",
            "Iteration 53, loss = 1.18854693\n",
            "Iteration 54, loss = 1.14830080\n",
            "Iteration 55, loss = 1.13797022\n",
            "Iteration 56, loss = 1.47081642\n",
            "Iteration 57, loss = 1.47539620\n",
            "Iteration 58, loss = 1.40838971\n",
            "Iteration 59, loss = 1.30101738\n",
            "Iteration 60, loss = 1.30479412\n",
            "Iteration 61, loss = 1.34553811\n",
            "Iteration 62, loss = 1.23707220\n",
            "Iteration 63, loss = 1.20286196\n",
            "Iteration 64, loss = 1.23715347\n",
            "Iteration 65, loss = 1.25984015\n",
            "Iteration 66, loss = 1.22231155\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 13.70940222\n",
            "Iteration 2, loss = 1.78215326\n",
            "Iteration 3, loss = 1.59684741\n",
            "Iteration 4, loss = 1.53625116\n",
            "Iteration 5, loss = 1.50016503\n",
            "Iteration 6, loss = 1.45315058\n",
            "Iteration 7, loss = 1.45726122\n",
            "Iteration 8, loss = 1.38806221\n",
            "Iteration 9, loss = 1.33306420\n",
            "Iteration 10, loss = 1.33994757\n",
            "Iteration 11, loss = 1.35684983\n",
            "Iteration 12, loss = 1.31340988\n",
            "Iteration 13, loss = 1.25756628\n",
            "Iteration 14, loss = 1.28317423\n",
            "Iteration 15, loss = 1.25940859\n",
            "Iteration 16, loss = 1.23405172\n",
            "Iteration 17, loss = 1.23600182\n",
            "Iteration 18, loss = 1.23463416\n",
            "Iteration 19, loss = 1.23729569\n",
            "Iteration 20, loss = 1.24001439\n",
            "Iteration 21, loss = 1.26511978\n",
            "Iteration 22, loss = 1.35177512\n",
            "Iteration 23, loss = 1.37772494\n",
            "Iteration 24, loss = 1.23394148\n",
            "Iteration 25, loss = 1.22322348\n",
            "Iteration 26, loss = 1.21571965\n",
            "Iteration 27, loss = 1.20094518\n",
            "Iteration 28, loss = 1.22036545\n",
            "Iteration 29, loss = 1.22542254\n",
            "Iteration 30, loss = 1.21178583\n",
            "Iteration 31, loss = 1.19056687\n",
            "Iteration 32, loss = 1.18938020\n",
            "Iteration 33, loss = 1.23281112\n",
            "Iteration 34, loss = 1.20579633\n",
            "Iteration 35, loss = 1.18835873\n",
            "Iteration 36, loss = 1.17829912\n",
            "Iteration 37, loss = 1.16972747\n",
            "Iteration 38, loss = 1.17426259\n",
            "Iteration 39, loss = 1.23629597\n",
            "Iteration 40, loss = 1.22785600\n",
            "Iteration 41, loss = 1.18327798\n",
            "Iteration 42, loss = 1.18489376\n",
            "Iteration 43, loss = 1.26793403\n",
            "Iteration 44, loss = 1.26744084\n",
            "Iteration 45, loss = 1.22365710\n",
            "Iteration 46, loss = 1.16944367\n",
            "Iteration 47, loss = 1.16954056\n",
            "Iteration 48, loss = 1.15517562\n",
            "Iteration 49, loss = 1.18575115\n",
            "Iteration 50, loss = 1.19599593\n",
            "Iteration 51, loss = 1.15914902\n",
            "Iteration 52, loss = 1.15295343\n",
            "Iteration 53, loss = 1.16500253\n",
            "Iteration 54, loss = 1.15214667\n",
            "Iteration 55, loss = 1.15155204\n",
            "Iteration 56, loss = 1.20668513\n",
            "Iteration 57, loss = 1.24003126\n",
            "Iteration 58, loss = 1.15234931\n",
            "Iteration 59, loss = 1.15505890\n",
            "Iteration 60, loss = 1.14325067\n",
            "Iteration 61, loss = 1.13912631\n",
            "Iteration 62, loss = 1.14742600\n",
            "Iteration 63, loss = 1.15141202\n",
            "Iteration 64, loss = 1.13612662\n",
            "Iteration 65, loss = 1.13178203\n",
            "Iteration 66, loss = 1.14420713\n",
            "Iteration 67, loss = 1.15336268\n",
            "Iteration 68, loss = 1.15146933\n",
            "Iteration 69, loss = 1.17336907\n",
            "Iteration 70, loss = 1.14116781\n",
            "Iteration 71, loss = 1.20498833\n",
            "Iteration 72, loss = 1.13814184\n",
            "Iteration 73, loss = 1.13451435\n",
            "Iteration 74, loss = 1.11433254\n",
            "Iteration 75, loss = 1.12592760\n",
            "Iteration 76, loss = 1.14993871\n",
            "Iteration 77, loss = 1.12545147\n",
            "Iteration 78, loss = 1.14284028\n",
            "Iteration 79, loss = 1.12579615\n",
            "Iteration 80, loss = 1.13377540\n",
            "Iteration 81, loss = 1.12923877\n",
            "Iteration 82, loss = 1.13041727\n",
            "Iteration 83, loss = 1.13360708\n",
            "Iteration 84, loss = 1.13171352\n",
            "Iteration 85, loss = 1.17331723\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 10.91751191\n",
            "Iteration 2, loss = 2.06882306\n",
            "Iteration 3, loss = 1.65936546\n",
            "Iteration 4, loss = 1.63525208\n",
            "Iteration 5, loss = 1.61431837\n",
            "Iteration 6, loss = 1.61297947\n",
            "Iteration 7, loss = 1.61840953\n",
            "Iteration 8, loss = 1.60052910\n",
            "Iteration 9, loss = 1.59004800\n",
            "Iteration 10, loss = 1.59413649\n",
            "Iteration 11, loss = 1.57938019\n",
            "Iteration 12, loss = 1.58695083\n",
            "Iteration 13, loss = 1.57378792\n",
            "Iteration 14, loss = 1.55977443\n",
            "Iteration 15, loss = 1.55273323\n",
            "Iteration 16, loss = 1.54969848\n",
            "Iteration 17, loss = 1.52605931\n",
            "Iteration 18, loss = 1.51883487\n",
            "Iteration 19, loss = 1.55114730\n",
            "Iteration 20, loss = 1.51124328\n",
            "Iteration 21, loss = 1.49594746\n",
            "Iteration 22, loss = 1.50560820\n",
            "Iteration 23, loss = 1.49325315\n",
            "Iteration 24, loss = 1.47989194\n",
            "Iteration 25, loss = 1.47111348\n",
            "Iteration 26, loss = 1.46265984\n",
            "Iteration 27, loss = 1.43964901\n",
            "Iteration 28, loss = 1.44219515\n",
            "Iteration 29, loss = 1.42087808\n",
            "Iteration 30, loss = 1.40061038\n",
            "Iteration 31, loss = 1.40728511\n",
            "Iteration 32, loss = 1.38929493\n",
            "Iteration 33, loss = 1.37705332\n",
            "Iteration 34, loss = 1.38688358\n",
            "Iteration 35, loss = 1.35765576\n",
            "Iteration 36, loss = 1.36661109\n",
            "Iteration 37, loss = 1.35860352\n",
            "Iteration 38, loss = 1.34173225\n",
            "Iteration 39, loss = 1.35100964\n",
            "Iteration 40, loss = 1.35595189\n",
            "Iteration 41, loss = 1.34020244\n",
            "Iteration 42, loss = 1.36854379\n",
            "Iteration 43, loss = 1.33728800\n",
            "Iteration 44, loss = 1.31389995\n",
            "Iteration 45, loss = 1.28194335\n",
            "Iteration 46, loss = 1.28633550\n",
            "Iteration 47, loss = 1.28381767\n",
            "Iteration 48, loss = 1.29240854\n",
            "Iteration 49, loss = 1.26462247\n",
            "Iteration 50, loss = 1.24290537\n",
            "Iteration 51, loss = 1.21800904\n",
            "Iteration 52, loss = 1.21829862\n",
            "Iteration 53, loss = 1.22428900\n",
            "Iteration 54, loss = 1.22111628\n",
            "Iteration 55, loss = 1.21948258\n",
            "Iteration 56, loss = 1.24730144\n",
            "Iteration 57, loss = 1.23078129\n",
            "Iteration 58, loss = 1.20530469\n",
            "Iteration 59, loss = 1.23499219\n",
            "Iteration 60, loss = 1.20493287\n",
            "Iteration 61, loss = 1.18716451\n",
            "Iteration 62, loss = 1.21449917\n",
            "Iteration 63, loss = 1.18331471\n",
            "Iteration 64, loss = 1.22716305\n",
            "Iteration 65, loss = 1.21352500\n",
            "Iteration 66, loss = 1.19511270\n",
            "Iteration 67, loss = 1.17392655\n",
            "Iteration 68, loss = 1.17402245\n",
            "Iteration 69, loss = 1.17299786\n",
            "Iteration 70, loss = 1.20731643\n",
            "Iteration 71, loss = 1.18317745\n",
            "Iteration 72, loss = 1.18129029\n",
            "Iteration 73, loss = 1.18247041\n",
            "Iteration 74, loss = 1.18792053\n",
            "Iteration 75, loss = 1.20252189\n",
            "Iteration 76, loss = 1.18236524\n",
            "Iteration 77, loss = 1.21396885\n",
            "Iteration 78, loss = 1.23032365\n",
            "Iteration 79, loss = 1.29518103\n",
            "Iteration 80, loss = 1.18795367\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1.73729815\n",
            "Iteration 2, loss = 1.53874962\n",
            "Iteration 3, loss = 1.47773682\n",
            "Iteration 4, loss = 1.43524171\n",
            "Iteration 5, loss = 1.40902424\n",
            "Iteration 6, loss = 1.37688425\n",
            "Iteration 7, loss = 1.35767798\n",
            "Iteration 8, loss = 1.31982114\n",
            "Iteration 9, loss = 1.28203628\n",
            "Iteration 10, loss = 1.24064722\n",
            "Iteration 11, loss = 1.22659157\n",
            "Iteration 12, loss = 1.18748180\n",
            "Iteration 13, loss = 1.15158866\n",
            "Iteration 14, loss = 1.10410207\n",
            "Iteration 15, loss = 1.08432758\n",
            "Iteration 16, loss = 1.07010535\n",
            "Iteration 17, loss = 0.99346562\n",
            "Iteration 18, loss = 0.96635837\n",
            "Iteration 19, loss = 0.92057931\n",
            "Iteration 20, loss = 0.89815884\n",
            "Iteration 21, loss = 0.89572755\n",
            "Iteration 22, loss = 0.81596863\n",
            "Iteration 23, loss = 0.76282111\n",
            "Iteration 24, loss = 0.74487551\n",
            "Iteration 25, loss = 0.75080943\n",
            "Iteration 26, loss = 0.73900065\n",
            "Iteration 27, loss = 0.71641966\n",
            "Iteration 28, loss = 0.64618040\n",
            "Iteration 29, loss = 0.60674402\n",
            "Iteration 30, loss = 0.56208981\n",
            "Iteration 31, loss = 0.59052889\n",
            "Iteration 32, loss = 0.58512635\n",
            "Iteration 33, loss = 0.53684010\n",
            "Iteration 34, loss = 0.51195127\n",
            "Iteration 35, loss = 0.51263256\n",
            "Iteration 36, loss = 0.50189827\n",
            "Iteration 37, loss = 0.51069434\n",
            "Iteration 38, loss = 0.44483493\n",
            "Iteration 39, loss = 0.44850562\n",
            "Iteration 40, loss = 0.41468297\n",
            "Iteration 41, loss = 0.35786283\n",
            "Iteration 42, loss = 0.36817056\n",
            "Iteration 43, loss = 0.35924438\n",
            "Iteration 44, loss = 0.46381754\n",
            "Iteration 45, loss = 0.43287095\n",
            "Iteration 46, loss = 0.41420956\n",
            "Iteration 47, loss = 0.38356858\n",
            "Iteration 48, loss = 0.38439567\n",
            "Iteration 49, loss = 0.37599442\n",
            "Iteration 50, loss = 0.35369648\n",
            "Iteration 51, loss = 0.32630873\n",
            "Iteration 52, loss = 0.31615208\n",
            "Iteration 53, loss = 0.28458893\n",
            "Iteration 54, loss = 0.28985791\n",
            "Iteration 55, loss = 0.34153499\n",
            "Iteration 56, loss = 0.35764328\n",
            "Iteration 57, loss = 0.28678942\n",
            "Iteration 58, loss = 0.26259733\n",
            "Iteration 59, loss = 0.23409370\n",
            "Iteration 60, loss = 0.20236576\n",
            "Iteration 61, loss = 0.22691089\n",
            "Iteration 62, loss = 0.34792299\n",
            "Iteration 63, loss = 0.34840311\n",
            "Iteration 64, loss = 0.27346269\n",
            "Iteration 65, loss = 0.23911676\n",
            "Iteration 66, loss = 0.24272187\n",
            "Iteration 67, loss = 0.23112496\n",
            "Iteration 68, loss = 0.24454040\n",
            "Iteration 69, loss = 0.20255269\n",
            "Iteration 70, loss = 0.16314105\n",
            "Iteration 71, loss = 0.16830591\n",
            "Iteration 72, loss = 0.20750499\n",
            "Iteration 73, loss = 0.23771213\n",
            "Iteration 74, loss = 0.32715709\n",
            "Iteration 75, loss = 0.33385423\n",
            "Iteration 76, loss = 0.27018217\n",
            "Iteration 77, loss = 0.18785670\n",
            "Iteration 78, loss = 0.14211922\n",
            "Iteration 79, loss = 0.12933605\n",
            "Iteration 80, loss = 0.10615855\n",
            "Iteration 81, loss = 0.08871558\n",
            "Iteration 82, loss = 0.06842678\n",
            "Iteration 83, loss = 0.09813987\n",
            "Iteration 84, loss = 0.13001208\n",
            "Iteration 85, loss = 0.19065196\n",
            "Iteration 86, loss = 0.28823583\n",
            "Iteration 87, loss = 0.38025417\n",
            "Iteration 88, loss = 0.31515314\n",
            "Iteration 89, loss = 0.28236678\n",
            "Iteration 90, loss = 0.27790914\n",
            "Iteration 91, loss = 0.21438838\n",
            "Iteration 92, loss = 0.26579730\n",
            "Iteration 93, loss = 0.24913864\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1.97767614\n",
            "Iteration 2, loss = 1.62839671\n",
            "Iteration 3, loss = 1.56254962\n",
            "Iteration 4, loss = 1.50167860\n",
            "Iteration 5, loss = 1.48410565\n",
            "Iteration 6, loss = 1.44703061\n",
            "Iteration 7, loss = 1.41002350\n",
            "Iteration 8, loss = 1.38798928\n",
            "Iteration 9, loss = 1.36925010\n",
            "Iteration 10, loss = 1.33674488\n",
            "Iteration 11, loss = 1.32556498\n",
            "Iteration 12, loss = 1.29480611\n",
            "Iteration 13, loss = 1.25506290\n",
            "Iteration 14, loss = 1.22765546\n",
            "Iteration 15, loss = 1.24320844\n",
            "Iteration 16, loss = 1.20434710\n",
            "Iteration 17, loss = 1.14461186\n",
            "Iteration 18, loss = 1.15650625\n",
            "Iteration 19, loss = 1.10111107\n",
            "Iteration 20, loss = 1.12283152\n",
            "Iteration 21, loss = 1.06871843\n",
            "Iteration 22, loss = 1.05412604\n",
            "Iteration 23, loss = 1.03607180\n",
            "Iteration 24, loss = 1.01885885\n",
            "Iteration 25, loss = 0.97454698\n",
            "Iteration 26, loss = 0.97229512\n",
            "Iteration 27, loss = 0.98161781\n",
            "Iteration 28, loss = 0.97542679\n",
            "Iteration 29, loss = 0.95384208\n",
            "Iteration 30, loss = 0.89934251\n",
            "Iteration 31, loss = 0.86260353\n",
            "Iteration 32, loss = 0.85100185\n",
            "Iteration 33, loss = 0.82453511\n",
            "Iteration 34, loss = 0.81144758\n",
            "Iteration 35, loss = 0.82744295\n",
            "Iteration 36, loss = 0.82072722\n",
            "Iteration 37, loss = 0.76629918\n",
            "Iteration 38, loss = 0.71590994\n",
            "Iteration 39, loss = 0.71560243\n",
            "Iteration 40, loss = 0.72515795\n",
            "Iteration 41, loss = 0.72350099\n",
            "Iteration 42, loss = 0.76812487\n",
            "Iteration 43, loss = 0.65377136\n",
            "Iteration 44, loss = 0.61472867\n",
            "Iteration 45, loss = 0.65121741\n",
            "Iteration 46, loss = 0.66062226\n",
            "Iteration 47, loss = 0.66106030\n",
            "Iteration 48, loss = 0.63803580\n",
            "Iteration 49, loss = 0.65797539\n",
            "Iteration 50, loss = 0.73210542\n",
            "Iteration 51, loss = 0.65584585\n",
            "Iteration 52, loss = 0.61004220\n",
            "Iteration 53, loss = 0.63570998\n",
            "Iteration 54, loss = 0.52490880\n",
            "Iteration 55, loss = 0.54681846\n",
            "Iteration 56, loss = 0.52297675\n",
            "Iteration 57, loss = 0.52835885\n",
            "Iteration 58, loss = 0.53662896\n",
            "Iteration 59, loss = 0.54829266\n",
            "Iteration 60, loss = 0.60881524\n",
            "Iteration 61, loss = 0.57328708\n",
            "Iteration 62, loss = 0.54951070\n",
            "Iteration 63, loss = 0.53579189\n",
            "Iteration 64, loss = 0.49843995\n",
            "Iteration 65, loss = 0.49611968\n",
            "Iteration 66, loss = 0.49981676\n",
            "Iteration 67, loss = 0.49462726\n",
            "Iteration 68, loss = 0.52532899\n",
            "Iteration 69, loss = 0.50424895\n",
            "Iteration 70, loss = 0.70278485\n",
            "Iteration 71, loss = 0.62145607\n",
            "Iteration 72, loss = 0.54455788\n",
            "Iteration 73, loss = 0.47912763\n",
            "Iteration 74, loss = 0.39291403\n",
            "Iteration 75, loss = 0.42323722\n",
            "Iteration 76, loss = 0.39463694\n",
            "Iteration 77, loss = 0.49502658\n",
            "Iteration 78, loss = 0.55938847\n",
            "Iteration 79, loss = 0.58549432\n",
            "Iteration 80, loss = 0.52747015\n",
            "Iteration 81, loss = 0.43967699\n",
            "Iteration 82, loss = 0.49345763\n",
            "Iteration 83, loss = 0.50113222\n",
            "Iteration 84, loss = 0.44651577\n",
            "Iteration 85, loss = 0.46254956\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "weights :  [0.14766581 0.15059835 0.14275627 0.12776007 0.09592801 0.13962949\n",
            " 0.09867518 0.09698681]\n",
            "Indivisual model performence :  [0.55614988 0.56719464 0.53765922 0.48117941 0.36129117 0.5258829\n",
            " 0.37163775 0.3652789 ]\n",
            "Ensemble accuracy: 0.6237623762376238\n",
            "Ensemble probabilities:\n",
            " [[6.08096742e-01 1.70880340e-01 2.56613784e-02 ... 3.60601470e-03\n",
            "  3.46890645e-03 5.60759317e-03]\n",
            " [1.43348556e-01 1.73847327e-01 4.53326196e-03 ... 2.32927192e-02\n",
            "  1.80349826e-03 4.08719560e-02]\n",
            " [4.00663723e-01 3.51652161e-01 9.82581687e-03 ... 4.48114717e-03\n",
            "  2.31613490e-03 1.00976325e-02]\n",
            " ...\n",
            " [1.04284307e-01 1.02150484e-01 3.31931470e-04 ... 4.21325431e-03\n",
            "  5.16048950e-05 1.12462734e-01]\n",
            " [1.86403604e-01 1.28593079e-01 2.06211888e-02 ... 2.32569846e-02\n",
            "  7.15438711e-03 4.17599890e-02]\n",
            " [1.21821096e-01 3.64626771e-02 1.59248288e-04 ... 3.36438883e-03\n",
            "  1.40390666e-04 4.62484425e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single Neural network Model:"
      ],
      "metadata": {
        "id": "r2nPeQ6tqC9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train single NN model on mean stats of train dataset:\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "\n",
        "random_state=1234\n",
        "model = MLPClassifier(hidden_layer_sizes=(256,128,64,32), activation='relu', solver='adam', max_iter=200, learning_rate_init=0.01, early_stopping=False , verbose=True, random_state=random_state)#, batch_size=32, learning_rate='adaptive')\n",
        "model_type = 'single'\n",
        "\n",
        "model.fit(X_train_list[0], y_train_list[0].astype(int))"
      ],
      "metadata": {
        "id": "dRwqprsKqHtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation:"
      ],
      "metadata": {
        "id": "U-x6ctN5r0a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if model_type == 'ensemble':\n",
        "  y_pred_crop = model.predict_prob(X_test_list)\n",
        "  y_pred_crop = y_pred_crop.argmax(axis=1)\n",
        "  print(classification_report(y_test_list[0],y_pred_crop))\n",
        "elif model_type == 'single':\n",
        "  y_pred_crop =  model.predict(X_test_list[0])\n",
        "  print(classification_report(y_test_list[0],y_pred_crop))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5El2ch-r5yK",
        "outputId": "92cc17ff-2a94-42f0-ea7a-6263f34c02ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.83      0.69       400\n",
            "           1       0.35      0.09      0.14       181\n",
            "           2       0.00      0.00      0.00        25\n",
            "           3       0.68      0.81      0.74       351\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00        39\n",
            "           6       0.00      0.00      0.00        12\n",
            "           7       0.67      0.89      0.76        65\n",
            "           8       0.00      0.00      0.00         9\n",
            "           9       0.00      0.00      0.00         2\n",
            "          10       0.00      0.00      0.00         6\n",
            "          11       0.00      0.00      0.00         3\n",
            "          12       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.62      1111\n",
            "   macro avg       0.18      0.20      0.18      1111\n",
            "weighted avg       0.52      0.62      0.55      1111\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance:"
      ],
      "metadata": {
        "id": "QiQIGToJuT52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.base import is_classifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def softmax_stable(x):\n",
        "    return(np.exp(x - np.max(x)) / np.exp(x - np.max(x)).sum())\n",
        "\n",
        "def permutation_importance(model, X, y, n_iter=5, random_state=None, scoring=None):\n",
        "    if scoring is None:\n",
        "        scoring = accuracy_score if is_classifier(model) else mean_absolute_error\n",
        "\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    baseline_score = scoring(y, model.predict(X))\n",
        "    feature_importances = np.zeros(X.shape[1])\n",
        "\n",
        "    for feature_idx in range(X.shape[1]):\n",
        "        scores = np.zeros(n_iter)\n",
        "        for iter_idx in range(n_iter):\n",
        "            X_permuted = X.copy()\n",
        "            np.random.shuffle(X_permuted[:, feature_idx])\n",
        "            permuted_score = scoring(y, model.predict(X_permuted))\n",
        "            scores[iter_idx] = permuted_score - baseline_score\n",
        "        feature_importances[feature_idx] = np.mean(scores)\n",
        "\n",
        "    return feature_importances"
      ],
      "metadata": {
        "id": "gHS6E7rZuXTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate permutation importance\n",
        "if model_type == 'ensemble':\n",
        "  importances = permutation_importance(model.models[0], X_test_list[0].to_numpy(), y_test_list[0], n_iter=5, random_state=42)\n",
        "else:\n",
        "  importances = permutation_importance(model, X_test_list[0].to_numpy(), y_test_list[0], n_iter=5, random_state=42)\n",
        "\n",
        "# Print feature importances\n",
        "print(\"Permutation importance of each feature:\\n\", importances)\n",
        "print(\"Permutation importance of each feature (softmax):\\n\", softmax_stable(importances))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM0CQc9suaT_",
        "outputId": "1bc4e354-1e91-489d-ba54-e4d79abada48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Permutation importance of each feature:\n",
            " [-0.00018002 -0.00252025 -0.0090009  -0.050045   -0.01026103 -0.00288029\n",
            " -0.01026103 -0.00432043 -0.01116112  0.0039604  -0.16867687 -0.0129613\n",
            "  0.00108011  0.00018002 -0.00054005  0.00252025 -0.00090009  0.00108011\n",
            " -0.00072007  0.         -0.00108011  0.00378038  0.00162016 -0.00108011\n",
            "  0.00054005]\n",
            "Permutation importance of each feature (softmax):\n",
            " [0.04040788 0.04031343 0.04005301 0.03844235 0.04000257 0.04029892\n",
            " 0.04000257 0.04024092 0.03996658 0.04057553 0.03414199 0.0398947\n",
            " 0.04045883 0.04042243 0.04039333 0.04051714 0.04037879 0.04045883\n",
            " 0.04038606 0.04041515 0.04037153 0.04056823 0.04048069 0.04037153\n",
            " 0.04043699]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare and Submit test data results:"
      ],
      "metadata": {
        "id": "kHdzxzWtu2h_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open (f'{main}/{test_label_collection}/collection.json') as f:\n",
        "    test_json = json.load(f)\n",
        "    \n",
        "test_folder_ids = [i['href'].split('_')[-1].split('.')[0] for i in test_json['links'][4:]]\n",
        "\n",
        "test_field_paths = [f'{main}/{test_label_collection}/{test_label_collection}_{i}/field_ids.tif' for i in test_folder_ids]"
      ],
      "metadata": {
        "id": "-mym5KIkvCA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "competition_test_data = pd.DataFrame(test_folder_ids , columns=['unique_folder_id'])\n",
        "competition_test_data['field_paths'] = test_field_paths\n",
        "competition_test_data.drop(707, inplace=True)\n",
        "competition_test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dkdzZLYPvFXb",
        "outputId": "cef07ff8-273d-4990-8f9d-90dfdcf78d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  unique_folder_id                                        field_paths\n",
              "0            6199c  ref_agrifieldnet_competition_v1/ref_agrifieldn...\n",
              "1            6c81d  ref_agrifieldnet_competition_v1/ref_agrifieldn...\n",
              "2            1ebeb  ref_agrifieldnet_competition_v1/ref_agrifieldn...\n",
              "3            586a2  ref_agrifieldnet_competition_v1/ref_agrifieldn...\n",
              "4            65812  ref_agrifieldnet_competition_v1/ref_agrifieldn..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fecff56d-af4b-4a4b-a1f1-35d2622bed72\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_folder_id</th>\n",
              "      <th>field_paths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6199c</td>\n",
              "      <td>ref_agrifieldnet_competition_v1/ref_agrifieldn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6c81d</td>\n",
              "      <td>ref_agrifieldnet_competition_v1/ref_agrifieldn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1ebeb</td>\n",
              "      <td>ref_agrifieldnet_competition_v1/ref_agrifieldn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>586a2</td>\n",
              "      <td>ref_agrifieldnet_competition_v1/ref_agrifieldn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65812</td>\n",
              "      <td>ref_agrifieldnet_competition_v1/ref_agrifieldn...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fecff56d-af4b-4a4b-a1f1-35d2622bed72')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fecff56d-af4b-4a4b-a1f1-35d2622bed72 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fecff56d-af4b-4a4b-a1f1-35d2622bed72');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = feature_extractor(competition_test_data,  source_collection)\n",
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "wztiBECSvN0I",
        "outputId": "b928b1f6-6582-4cf5-8bbc-b5157f9f7260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "707it [01:29,  7.89it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       B01  B02  B03  B04  B05  B06  B07  B08  B8A  B09  B11  B12  field_id\n",
              "35283   39   35   35   35   38   48   55   59   60   11   53   39    5407.0\n",
              "35284   39   34   33   34   37   49   58   58   63   11   54   40    5407.0\n",
              "35538   39   36   36   37   39   59   70   56   76   14   55   37    5407.0\n",
              "35539   39   35   36   34   39   59   70   75   76   14   55   37    5407.0\n",
              "35540   39   33   34   31   37   70   85   79   90   14   54   34    5407.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae2411d8-3f44-4ef1-a297-034c5c0b3e28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B01</th>\n",
              "      <th>B02</th>\n",
              "      <th>B03</th>\n",
              "      <th>B04</th>\n",
              "      <th>B05</th>\n",
              "      <th>B06</th>\n",
              "      <th>B07</th>\n",
              "      <th>B08</th>\n",
              "      <th>B8A</th>\n",
              "      <th>B09</th>\n",
              "      <th>B11</th>\n",
              "      <th>B12</th>\n",
              "      <th>field_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35283</th>\n",
              "      <td>39</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>38</td>\n",
              "      <td>48</td>\n",
              "      <td>55</td>\n",
              "      <td>59</td>\n",
              "      <td>60</td>\n",
              "      <td>11</td>\n",
              "      <td>53</td>\n",
              "      <td>39</td>\n",
              "      <td>5407.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35284</th>\n",
              "      <td>39</td>\n",
              "      <td>34</td>\n",
              "      <td>33</td>\n",
              "      <td>34</td>\n",
              "      <td>37</td>\n",
              "      <td>49</td>\n",
              "      <td>58</td>\n",
              "      <td>58</td>\n",
              "      <td>63</td>\n",
              "      <td>11</td>\n",
              "      <td>54</td>\n",
              "      <td>40</td>\n",
              "      <td>5407.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35538</th>\n",
              "      <td>39</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>37</td>\n",
              "      <td>39</td>\n",
              "      <td>59</td>\n",
              "      <td>70</td>\n",
              "      <td>56</td>\n",
              "      <td>76</td>\n",
              "      <td>14</td>\n",
              "      <td>55</td>\n",
              "      <td>37</td>\n",
              "      <td>5407.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35539</th>\n",
              "      <td>39</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>34</td>\n",
              "      <td>39</td>\n",
              "      <td>59</td>\n",
              "      <td>70</td>\n",
              "      <td>75</td>\n",
              "      <td>76</td>\n",
              "      <td>14</td>\n",
              "      <td>55</td>\n",
              "      <td>37</td>\n",
              "      <td>5407.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35540</th>\n",
              "      <td>39</td>\n",
              "      <td>33</td>\n",
              "      <td>34</td>\n",
              "      <td>31</td>\n",
              "      <td>37</td>\n",
              "      <td>70</td>\n",
              "      <td>85</td>\n",
              "      <td>79</td>\n",
              "      <td>90</td>\n",
              "      <td>14</td>\n",
              "      <td>54</td>\n",
              "      <td>34</td>\n",
              "      <td>5407.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae2411d8-3f44-4ef1-a297-034c5c0b3e28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae2411d8-3f44-4ef1-a297-034c5c0b3e28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae2411d8-3f44-4ef1-a297-034c5c0b3e28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add_preprocessing_features(test_data)\n",
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "0Jxtq8h5vPXg",
        "outputId": "35f5061e-e7c3-4dce-997f-ef82833472bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       B01  B02  B03  B04  B05  B06  B07  B08  B8A  B09  ...      SIPI  \\\n",
              "35283   39   35   35   35   38   48   55   59   60   11  ...  1.000000   \n",
              "35284   39   34   33   34   37   49   58   58   63   11  ...  1.000000   \n",
              "35538   39   36   36   37   39   59   70   56   76   14  ...  1.052632   \n",
              "35539   39   35   36   34   39   59   70   75   76   14  ...  0.975610   \n",
              "35540   39   33   34   31   37   70   85   79   90   14  ...  0.958333   \n",
              "\n",
              "            S2REP      CCCI       HUE    RENDVI      RECI       EVI      EVI2  \\\n",
              "35283  729.500000  0.847938  0.000000  0.116279  0.685714  8.000000  0.606316   \n",
              "35284  731.250000  0.847368  1.570167  0.139535  0.705882  7.500000  0.619355   \n",
              "35538  730.375000  0.875900  1.570139  0.204082  0.513514  5.277778  0.485106   \n",
              "35539  727.750000  0.839538  1.488990  0.204082  1.205882  5.857143  0.894545   \n",
              "35540  727.272727  0.829741  1.517894  0.308411  1.548387  6.486486  1.037838   \n",
              "\n",
              "           NDWI     NPCRI  \n",
              "35283  0.000000  2.468085  \n",
              "35284  0.000000  2.538462  \n",
              "35538  0.013699  2.565217  \n",
              "35539  3.695652  1.954955  \n",
              "35540  3.968750  1.867257  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75eea5f6-728b-4480-86db-20b9d2c5decf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B01</th>\n",
              "      <th>B02</th>\n",
              "      <th>B03</th>\n",
              "      <th>B04</th>\n",
              "      <th>B05</th>\n",
              "      <th>B06</th>\n",
              "      <th>B07</th>\n",
              "      <th>B08</th>\n",
              "      <th>B8A</th>\n",
              "      <th>B09</th>\n",
              "      <th>...</th>\n",
              "      <th>SIPI</th>\n",
              "      <th>S2REP</th>\n",
              "      <th>CCCI</th>\n",
              "      <th>HUE</th>\n",
              "      <th>RENDVI</th>\n",
              "      <th>RECI</th>\n",
              "      <th>EVI</th>\n",
              "      <th>EVI2</th>\n",
              "      <th>NDWI</th>\n",
              "      <th>NPCRI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35283</th>\n",
              "      <td>39</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>35</td>\n",
              "      <td>38</td>\n",
              "      <td>48</td>\n",
              "      <td>55</td>\n",
              "      <td>59</td>\n",
              "      <td>60</td>\n",
              "      <td>11</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>729.500000</td>\n",
              "      <td>0.847938</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.606316</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.468085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35284</th>\n",
              "      <td>39</td>\n",
              "      <td>34</td>\n",
              "      <td>33</td>\n",
              "      <td>34</td>\n",
              "      <td>37</td>\n",
              "      <td>49</td>\n",
              "      <td>58</td>\n",
              "      <td>58</td>\n",
              "      <td>63</td>\n",
              "      <td>11</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>731.250000</td>\n",
              "      <td>0.847368</td>\n",
              "      <td>1.570167</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>0.619355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.538462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35538</th>\n",
              "      <td>39</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>37</td>\n",
              "      <td>39</td>\n",
              "      <td>59</td>\n",
              "      <td>70</td>\n",
              "      <td>56</td>\n",
              "      <td>76</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>1.052632</td>\n",
              "      <td>730.375000</td>\n",
              "      <td>0.875900</td>\n",
              "      <td>1.570139</td>\n",
              "      <td>0.204082</td>\n",
              "      <td>0.513514</td>\n",
              "      <td>5.277778</td>\n",
              "      <td>0.485106</td>\n",
              "      <td>0.013699</td>\n",
              "      <td>2.565217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35539</th>\n",
              "      <td>39</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>34</td>\n",
              "      <td>39</td>\n",
              "      <td>59</td>\n",
              "      <td>70</td>\n",
              "      <td>75</td>\n",
              "      <td>76</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.975610</td>\n",
              "      <td>727.750000</td>\n",
              "      <td>0.839538</td>\n",
              "      <td>1.488990</td>\n",
              "      <td>0.204082</td>\n",
              "      <td>1.205882</td>\n",
              "      <td>5.857143</td>\n",
              "      <td>0.894545</td>\n",
              "      <td>3.695652</td>\n",
              "      <td>1.954955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35540</th>\n",
              "      <td>39</td>\n",
              "      <td>33</td>\n",
              "      <td>34</td>\n",
              "      <td>31</td>\n",
              "      <td>37</td>\n",
              "      <td>70</td>\n",
              "      <td>85</td>\n",
              "      <td>79</td>\n",
              "      <td>90</td>\n",
              "      <td>14</td>\n",
              "      <td>...</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>727.272727</td>\n",
              "      <td>0.829741</td>\n",
              "      <td>1.517894</td>\n",
              "      <td>0.308411</td>\n",
              "      <td>1.548387</td>\n",
              "      <td>6.486486</td>\n",
              "      <td>1.037838</td>\n",
              "      <td>3.968750</td>\n",
              "      <td>1.867257</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75eea5f6-728b-4480-86db-20b9d2c5decf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75eea5f6-728b-4480-86db-20b9d2c5decf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75eea5f6-728b-4480-86db-20b9d2c5decf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats = ['mean', 'median', 'std', 'min', 'max', 'mode', 'skew', 'kurt']\n",
        "datasets = [get_dataset(test_data, None, stat) for stat in stats]\n",
        "Field_ids = datasets[0].field_id\n",
        "\n",
        "#Prepare datasets:\n",
        "datasets = [get_dataset_np(ds) for ds in datasets]\n",
        "\n",
        "# Perform train-test split for each dataset\n",
        "X_list, _ = zip(*datasets)"
      ],
      "metadata": {
        "id": "cqOGdCH6vWtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#re-labeled classes:\n",
        "crop_dict = {\n",
        " 0: 'Wheat',\n",
        " 1: 'Mustac',\n",
        " 2: 'Lentil',\n",
        " 3: 'No crop/Fallow',\n",
        " 4: 'Green pea',\n",
        " 5: 'Sugarcane',\n",
        " 6: 'Garlic',\n",
        " 7: 'Maize',\n",
        " 8: 'Gram',\n",
        " 9: 'Coriander',\n",
        " 10: 'Potato',\n",
        " 11: 'Bersem',\n",
        " 12: 'Rice'}"
      ],
      "metadata": {
        "id": "01-Se6GIvdBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def labeler(labeled):\n",
        "    crop_label = np.array([crop_dict.get(f'{int(i)}') for i in labeled])\n",
        "    return crop_label"
      ],
      "metadata": {
        "id": "NVFHu1spvi2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model_type == 'ensemble':\n",
        "  predictions = model.predict_prob(X_list)\n",
        "  crop_columns = [crop_dict.get(i) for i in range(13)]\n",
        "elif model_type == 'single':\n",
        "  predictions = model.predict_proba(X_list[0].drop('field_id', axis=1 ))\n",
        "  crop_columns = [crop_dict.get(i) for i in model.classes_]\n",
        "\n",
        "test_df  = pd.DataFrame(columns= ['field_id'] + crop_columns)\n",
        "test_df['field_id'] = Field_ids\n",
        "test_df[crop_columns]= predictions \n",
        "test_df.to_csv('submission.csv', index=False)\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "ONGHhGckvqlC",
        "outputId": "78b1ac5d-747e-4d12-a071-d436631e4ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  field_id     Wheat    Mustac    Lentil  No crop/Fallow  Green pea  \\\n",
              "0       11  0.290678  0.231920  0.029039        0.267506   0.007299   \n",
              "1       13  0.413412  0.125180  0.062089        0.349690   0.005854   \n",
              "2       19  0.424064  0.224369  0.036572        0.212582   0.006160   \n",
              "3       21  0.245387  0.158054  0.023952        0.281237   0.007500   \n",
              "4       25  0.344387  0.106630  0.018291        0.492958   0.003607   \n",
              "\n",
              "   Sugarcane    Garlic     Maize      Gram  Coriander    Potato    Bersem  \\\n",
              "0   0.104186  0.002751  0.013500  0.001682   0.002007  0.012949  0.005366   \n",
              "1   0.018281  0.003927  0.001268  0.004147   0.002808  0.002589  0.003930   \n",
              "2   0.058677  0.004885  0.004869  0.003366   0.002666  0.006072  0.004908   \n",
              "3   0.218110  0.002650  0.015262  0.001836   0.001612  0.012064  0.005001   \n",
              "4   0.012806  0.003858  0.000889  0.003572   0.001682  0.001725  0.004306   \n",
              "\n",
              "       Rice  \n",
              "0  0.031118  \n",
              "1  0.006824  \n",
              "2  0.010812  \n",
              "3  0.027336  \n",
              "4  0.005287  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b35ff80-b3bb-451e-9e0f-f191887c0c94\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>field_id</th>\n",
              "      <th>Wheat</th>\n",
              "      <th>Mustac</th>\n",
              "      <th>Lentil</th>\n",
              "      <th>No crop/Fallow</th>\n",
              "      <th>Green pea</th>\n",
              "      <th>Sugarcane</th>\n",
              "      <th>Garlic</th>\n",
              "      <th>Maize</th>\n",
              "      <th>Gram</th>\n",
              "      <th>Coriander</th>\n",
              "      <th>Potato</th>\n",
              "      <th>Bersem</th>\n",
              "      <th>Rice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>0.290678</td>\n",
              "      <td>0.231920</td>\n",
              "      <td>0.029039</td>\n",
              "      <td>0.267506</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.104186</td>\n",
              "      <td>0.002751</td>\n",
              "      <td>0.013500</td>\n",
              "      <td>0.001682</td>\n",
              "      <td>0.002007</td>\n",
              "      <td>0.012949</td>\n",
              "      <td>0.005366</td>\n",
              "      <td>0.031118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>0.413412</td>\n",
              "      <td>0.125180</td>\n",
              "      <td>0.062089</td>\n",
              "      <td>0.349690</td>\n",
              "      <td>0.005854</td>\n",
              "      <td>0.018281</td>\n",
              "      <td>0.003927</td>\n",
              "      <td>0.001268</td>\n",
              "      <td>0.004147</td>\n",
              "      <td>0.002808</td>\n",
              "      <td>0.002589</td>\n",
              "      <td>0.003930</td>\n",
              "      <td>0.006824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>0.424064</td>\n",
              "      <td>0.224369</td>\n",
              "      <td>0.036572</td>\n",
              "      <td>0.212582</td>\n",
              "      <td>0.006160</td>\n",
              "      <td>0.058677</td>\n",
              "      <td>0.004885</td>\n",
              "      <td>0.004869</td>\n",
              "      <td>0.003366</td>\n",
              "      <td>0.002666</td>\n",
              "      <td>0.006072</td>\n",
              "      <td>0.004908</td>\n",
              "      <td>0.010812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21</td>\n",
              "      <td>0.245387</td>\n",
              "      <td>0.158054</td>\n",
              "      <td>0.023952</td>\n",
              "      <td>0.281237</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.218110</td>\n",
              "      <td>0.002650</td>\n",
              "      <td>0.015262</td>\n",
              "      <td>0.001836</td>\n",
              "      <td>0.001612</td>\n",
              "      <td>0.012064</td>\n",
              "      <td>0.005001</td>\n",
              "      <td>0.027336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "      <td>0.344387</td>\n",
              "      <td>0.106630</td>\n",
              "      <td>0.018291</td>\n",
              "      <td>0.492958</td>\n",
              "      <td>0.003607</td>\n",
              "      <td>0.012806</td>\n",
              "      <td>0.003858</td>\n",
              "      <td>0.000889</td>\n",
              "      <td>0.003572</td>\n",
              "      <td>0.001682</td>\n",
              "      <td>0.001725</td>\n",
              "      <td>0.004306</td>\n",
              "      <td>0.005287</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b35ff80-b3bb-451e-9e0f-f191887c0c94')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b35ff80-b3bb-451e-9e0f-f191887c0c94 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b35ff80-b3bb-451e-9e0f-f191887c0c94');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}